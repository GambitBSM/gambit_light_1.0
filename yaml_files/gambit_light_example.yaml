#####################################
## GAMBIT_light configuration example
#####################################


UserModel:

  p1:
    name: param_name_1
    # prior_type: flat
    # range: [0.0, 5.0]

  p2:
    name: param_name_2
    # prior_type: flat
    # range: [0.0, 5.0]

  p3: 
    name: param_name_3
    # fixed_value: 3.0

  p4:
    name: param_name_4
    # same_as: UserModel::p1

  p5-p7: 
    name: param_name_  # GAMBIT will generate the names "param_name_5", "param_name_6", etc.
    # prior_type: flat
    # range: [-1.0, 1.0]


# Instead of specifying individual parameter priors above, 
# a user-provided prior transform function can be used via 
# the "UserPrior" section below. The user-defined prior 
# function should take care of the prior transform 
# (from the unit hypercube) for all parameters in use.

UserPrior:

  lang: python
  user_lib: gambit_light_interface/example_python/example.py
  func_name: user_prior

  # lang: c
  # user_lib: gambit_light_interface/example_c/example.so
  # func_name: user_prior

  # lang: c++
  # user_lib: gambit_light_interface/example_cpp/example.so
  # func_name: user_prior

  # lang: fortran
  # user_lib: gambit_light_interface/example_fortran/example.so
  # func_name: user_prior


UserLogLikes:

  # Note: 
  # If a loglike function expects all the UserModel parameters 
  # as input, you can leave out the 'input' section (see below).

  py_user_loglike:
    lang: python
    user_lib: gambit_light_interface/example_python/example.py
    func_name: user_loglike
    input:
      - param_name_1
      - param_name_2
      - param_name_4
    output:
      - py_user_loglike_output_1
      - py_user_loglike_output_2
      - py_user_loglike_output_3


  py_user_loglike_rosenbrock:
    lang: python
    user_lib: gambit_light_interface/example_python/example_rosenbrock.py
    func_name: user_loglike
    input:
      - param_name_1
      - param_name_2
    output:
      - py_user_loglike_rosenbrock_output_1


  # c_user_loglike:
  #   lang: c
  #   user_lib: gambit_light_interface/example_c/example.so
  #   func_name: user_loglike
  #   input:
  #     - param_name_1
  #     - param_name_2
  #     - param_name_3
  #   output:
  #     - c_user_loglike_output_1
  #     - c_user_loglike_output_2
  #     - c_user_loglike_output_3


  # cpp_user_loglike:
  #   lang: c++
  #   user_lib: gambit_light_interface/example_cpp/example.so
  #   func_name: user_loglike
  #   input:
  #     - param_name_2
  #     - param_name_3
  #   output:
  #     - cpp_user_loglike_output_1
  #     - cpp_user_loglike_output_2
  #     # - cpp_user_loglike_output_3   # We can comment out an outputs if we 
  #                                     # don't want to include it in the scan output

  # fortran_user_loglike:
  #   lang: fortran
  #   user_lib: gambit_light_interface/example_fortran/example.so
  #   func_name: user_loglike
  #   input:
  #     - param_name_1
  #     - param_name_2
  #   output:
  #     - fortran_user_loglike_output_1


Printer:

  # printer: cout

  printer: hdf5
  options:
    output_file: "results.hdf5"
    group: "/data"
    buffer_length: 1000
    delete_file_on_restart: true

  # printer: hdf5_v1
  # options:
  #   output_file: "results.hdf5"
  #   group: "/data"
  #   delete_file_on_restart: true
  #   disable_combine_routines: false

  # printer: ascii
  # options:
  #   output_file: "results.dat"
  #   buffer_length: 10
  #   delete_file_on_restart: true


Scanner:

  use_scanner: random

  scanners:

    random:
      plugin: random
      point_number: 2                     # The number of points to be randomly selected. Default is 1000.

    diver:
      plugin: diver
      NP: 200                             # Population size (individuals per generation)
      convthresh: 1.e-3                   # Threshold for gen-level convergence: smoothed fractional improvement in the mean population value
      jDE: true                           # Use self-adaptive choices for rand/1/bin parameters as per Brest et al 2006
      lambdajDE: true                     # Use self-adaptive rand-to-best/1/bin parameters; based on Brest et al 2006
      maxgen: 5000                        # Maximum number of generations per civilisation
      maxciv: 1                           # Maximum number of civilisations
      Cr: 0.9                             # Crossover factor
      lambda: 0.0                         # Mixing factor between best and rand/current
      current: false                      # Use current vector for mutation
      expon: false                        # Use exponential crossover
      bndry: 3                            # Boundary constraint: 1=brick wall, 2=random re-initialization, 3=reflection
      convsteps: 10                       # Number of steps to smooth over when checking convergence
      removeDuplicates: true              # Weed out duplicate vectors within a single generation
      savecount: 1                        # Save progress every savecount generations
      full_native_output: true            # Output .raw file (Diver native sample output format)
      init_population_strategy: 2         # Initialisation strategy: 0=one shot, 1=n-shot, 2=n-shot with error if no valid vectors found.
      max_initialisation_attempts: 10000  # Maximum number of times to try to find a valid vector for each slot in the initial population.
      verbosity: 0                        # Output verbosity: 0=only error messages, 1=basic info, 2=civ-level info, 3+=population info
      seed: -1                            # Base seed for random number generation; non-positive means seed from the system clock

    polychord:
      plugin: polychord
      tol: 0.5                            # Stopping criterion (consistent with multinest)
      # nlive:                            # Number of live points. Default is 25 * <number of parameters>
      # nprior:                           # Number of prior samples to begin algorithm with. Default is 10 * nlive
      do_clustering: true                 # Whether or not to perform clustering
      fb: 1                               # Feedback level
      maxiter: -1                         # Max no. of iterations, a negative value means infinity
      maximise: false                     # Whether to run a maximisation algorithm once the run is finished
      outfile: true                       # Write output files?
      seed: -1                            # Seed for random number generator. Negative means seed from system time.

    multinest:
      plugin: multinest
      nlive: 1000                         # Number of live points
      tol: 0.5                            # Defines the stopping criteria
      IS: true                            # Do Nested Importance Sampling?
      mmodal: true                        # Do mode separation?
      ceff: false                         # Run in constant efficiency mode?
      efr: 0.8                            # Set the required efficiency
      nClsPar: 1                          # No. of parameters to do mode separation on; don't use more than 4
      updInt: 1000                        # After how many iterations feedback is required & the output files should be updated (*10 for dumper)
      maxModes: 100                       # Expected max no. of modes (used only for memory allocation)
      fb: false                           # Need feedback on standard output?
      outfile: true                       # Write output files?
      maxiter: -1                         # Max no. of iterations, a non-positive value means infinity.
      seed: -1                            # Random no. generator seed, if < 0 then take the seed from system clock

    twalk:
      plugin: twalk
      projection_dimension: 4             # The dimension of the space being projected onto.
      kwalk_ratio: 0.9836                 # The ratio of kwalk jumps to Gaussian jumps.
      gaussian_distance: 2.4              # The distance of the Gaussian jump.
      walk_distance: 2.5                  # The distance of the kwalk jump over a point.
      transverse_distance: 6.0            # The distance of the kwalk jump away from a point.
      hyper_grid: true                    # Confines the search to the hypercube defined by the priors.
      tolerance: 1.001                    # The accuracy of the second order moment (1 is perfect).
      burn_in: 0                          # Number of burn-in points that are not considered in the convergence.
      # chain_number:                     # The number of MCMC chains. Default is 1 + projection_dimension + number of MPI processes.

    jswarm:
      plugin: jswarm
      NP: 400                             # Population size (individuals per generation)
      adaptive_phi: true                  # Use self-optimising adaptive choices for phi1 and phi2
      adaptive_omega: true                # Use self-optimising adaptive choices for omega
      verbosity: 2                        # Output verbosity: 0=only error messages, 1=basic info, 2=generation-level info, 3+=particle-level info
      maxgen: 5000                        # Maximum number of generations
      omega: 0.7298                       # Inertial weight (default is Constriction Coefficient PSO)
      phi1: 1.5                           # Cognitive weight (default is Constriction Coefficient PSO)
      phi2: 1.5                           # Social weight (default is Constriction Coefficient PSO)
      bndry: 3                            # Boundary constraint: 1=brick wall, 2=random re-initialization, 3=reflection
      convthresh: 1.e-3                   # Threshold for gen-level convergence: smoothed fractional improvement in the mean personal best population value
      convsteps: 10                       # Number of steps to smooth over when checking convergence
      savecount: 1                        # Save progress every savecount generations
      init_population_strategy: 2         # Initialisation strategy: 0=one shot, 1=n-shot, 2=n-shot with error if no valid vectors found.
      init_stationary: false              # Initialise particle velocities to to zero
      max_initialisation_attempts: 10000  # Maximum number of times to try to find a valid vector for each slot in the initial population.
      allow_new_settings: false           # Allow settings to be overridden with new values when resuming
      save_particles_natively: false      # Save full particle data from every generation

    minuit2:
      plugin: minuit2
      tolerance: 0.0001                   # Stopping tolerance on parameters
      precision: 0.0001                   # Stopping precision on log-likelihood function
      max_loglike_calls: 100000           # Maximum number of calls of log-likelihood function
      max_iterations: 100000              # Maximum number of algorithm iterations
      algorithm: combined                 # Choice of minimization algorithm: simplex, combined, scan, fumili, bfgs, migrad
      print_level: 1                      # Verbosity for printing to the screen
      strategy: 2                         # Sets a collection of tolerance and precision parameters; see Minuit documentation
      start:                              # Starting point for model parameter
        UserModel::p1: 2.0
        UserModel::p2: 2.0
      step:                               # Starting step-size for model parameter
        UserModel::p1: 0.2
        UserModel::p2: 0.2

    scipy_basin_hopping:
      like: LogLike
      plugin: scipy_basin_hopping
      # The run arguments below have been tested with scipy v1.9. 
      # Other versions might expect different arguments.
      run:
        # n_runs: 4
        # x0:
        #   NormalDist::mu: 25.
        #   NormalDist::sigma: 2.5
        niter: 100
        T: 1.0
        stepsize: 0.5
        minimizer_kwargs:
          method: "L-BFGS-B"
        interval: 50
        disp: true
        target_accept_rate: 0.5
        stepwise_factor: 0.9

    scipy_differential_evolution:
      like: LogLike
      plugin: scipy_differential_evolution
      # The run arguments below have been tested with scipy v1.9. 
      # Other versions might expect different arguments.
      run:
        # n_runs: 4
        strategy: 'best1bin'
        maxiter: 1000
        popsize: 15
        tol: 0.01
        mutation: [0.5, 1]
        recombination: 0.7
        disp: false
        polish: true
        init: 'latinhypercube'
        atol: 0
        updating: 'immediate'
        # x0:
        #   NormalDist::mu: 25.
        #   NormalDist::sigma: 2.5

    scipy_direct:
      like: LogLike
      plugin: scipy_direct
      # The run arguments below have been tested with scipy v1.9. 
      # Other versions might expect different arguments.
      run:
        # n_runs: 4
        eps: 0.0001
        # maxfun: 2000
        maxiter: 1000
        locally_biased: true
        vol_tol: 1e-16
        len_tol: 1e-6

    scipy_dual_annealing:
      like: LogLike
      plugin: scipy_dual_annealing
      # The run arguments below have been tested with scipy v1.9. 
      # Other versions might expect different arguments.
      run:
        # n_runs: 4
        maxiter: 1000
        initial_temp: 5230.0
        restart_temp_ratio: 2.0e-5
        visit: 2.62
        accept: -5.0
        maxfun: 10000000.0
        no_local_search: false
        # x0:
        #   NormalDist::mu: 25.
        #   NormalDist::sigma: 2.5

    scipy_shgo:
      like: LogLike
      plugin: scipy_shgo
      # The run arguments below have been tested with scipy v1.9. 
      # Other versions might expect different arguments.
      run:
        split_param_space:
          NormalDist::mu: 2
          NormalDist::sigma: 2
        n: 100
        iters: 1
        sampling_method: "sobol"  # "simplicial", "halton", "sobol"
        minimizer_kwargs:
          method: "SLSQP" # "SLSQP" "L-BFGS-B"
          options:
            ftol: 1e-12
        options:
          # maxfev:
          # f_min:
          # f_tol:
          # maxiter:
          # maxev:
          # maxtime:
          # minhgrd:
          # jac: false  # Buggy in some scipy versions: https://github.com/scipy/scipy/issues/14533
          minimize_every_iter: true
          local_iter: false
          infty_constraints: true
          disp: false

    scipy_minimize:
      like: LogLike
      plugin: scipy_minimize
      # The run arguments below have been tested with scipy v1.9. 
      # Other versions might expect different arguments.
      run:
        # n_runs: 5
        # x0:
        #   NormalDist::mu: 25.
        #   NormalDist::sigma: 2.5
        method: "L-BFGS-B"  # "Nelder-Mead", "Powell", "CG", "BFGS", "L-BFGS-B", "TNC", "COBYLA", "SLSQP", "trust-constr",
        # jac: "2-point"      # "2-point", "3-point", "cs"
        # hess: "2-point"     # "2-point", "3-point", "cs"
        tol: 1e-6
        options:
          maxiter: 15000
          disp: false

    static_dynesty:
      like: LogLike
      pkg: gambit_dynesty
      plugin: static_dynesty
      pkl_name: "static_dynesty.pkl"
      init:
        nlive: 1000
      run:
        dlogz: 0.5
        checkpoint_every: 60
        
    dynamic_dynesty:
      like: LogLike
      plugin: dynamic_dynesty
      pkg: gambit_dynesty
      pkl_name: "dynamic_dynesty.pkl"
      init:
        nlive: 1000
      run:
        dlogz_init: 0.5
        n_effective: 10000
        checkpoint_every: 60

    nessai:
      like: LogLike
      plugin: nessai_flow_sampler
      pkg: gambit_nessai
      #init:
        #output: "nessai_log_dir"
        #logger: true

    nautilus:
      like: LogLike
      plugin: nautilus
      #pkg: gambit_nautilus
      run:
        verbose: true

    zeus:
      like: LogLike
      pkg: gambit_zeus
      plugin: zeus
      init:
        nwalkers: 8
      #run:
        #nsteps: 20000
        #filename: "zeus.h5"
      SaveProgressCallback:
        filename: zeus.h5
        ncheck: 100

    emcee:
      like: LogLike
      plugin: emcee
      pkg: gambit_emcee
      init:
        nwalkers: 8
      run:
        nsteps: 20000
        #filename: "emcee.h5"

    pocomc:
      like: LogLike
      plugin: pocomc
      #pkg: gambit_pocomc
      #init:
      #    nparticles: 1000

    ultranest:
      like: LogLike
      pkg: gambit_ultranest
      plugin: reactive_ultranest
      #init:
      run:
        min_num_live_points: 1000
        dlogz: 0.5


Logger:

  redirection:
    [Default]        : "default.log"
    [Scanner]        : "Scanner.log"


KeyValues:

  default_output_path: "runs/gambit_light_example"

  debug: false

  # An additional entry in the dataset and metadata, useful for identifying which
  # points correspond to a given scan in combined datasets.
  # The default is for print_scanID: true, 
  # and for it to print the date and time as an int of the form
  # scanID: HourMinuteSecondMillisecond. This can be overwritten to any integer.
  print_scanID: true
  # scanID: 1

  print_timing_data: true

  rng:
    generator: ranlux48
    seed: -1

  likelihood:
    model_invalid_for_lnlike_below: -5e5
    model_invalid_for_lnlike_below_alt: -5e5
    print_invalid_points: false

    # A 'likelihood modifier function' recieves as input the total
    # log-likelihood value and outputs a modified log-likelihood which
    # is then passed to the scanner. This can be used to make an adaptive
    # scanner explore specific ranges of the total log-likelihood, e.g.
    # log-likelihood values corresponding to a given 1D/2D confidence region.
    # The default is to use the 'identity' modifier, which does nothing.
    use_lnlike_modifier: identity
    lnlike_modifiers:
      # Assuming that the best-fit log-likelihood value is 0.0,
      # the 'gaussian' or 'gaussian_plateau' settings below
      # will encourage the scanner to explore parameter regions
      # at the border of the 2-sigma confidence region in 2D
      # (Delta lnlike = -3.09).
      gaussian:
        mu: -3.1
        sigma: 0.5
        # use_limit: lower
        use_delta_lnlike: false
      gaussian_plateau:
        mu_dn: -3.2
        sigma_dn: 0.5
        mu_up: -3.0
        sigma_up: 3.0
        use_delta_lnlike: false
